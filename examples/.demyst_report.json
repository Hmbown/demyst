{
  "timestamp": "2025-12-07T16:03:52.372353",
  "repository": "demyst",
  "branch": "main",
  "commit": "a4477704d9dea331a87b950ac9c10fcc659010b0",
  "files_analyzed": 8,
  "total_issues": 25,
  "blocking_issues": 18,
  "critical_issues": 18,
  "warning_issues": 7,
  "checks": [
    {
      "name": "Computational Mirages",
      "passed": false,
      "severity": "critical",
      "issues": [
        {
          "type": "mean",
          "line": 25,
          "function": "analyze_swarm_safety",
          "description": "Reduction on array-like data without accompanying dispersion check.",
          "recommendation": "Use VariationTensor to preserve statistical metadata during aggregations",
          "confidence": "medium",
          "blocking": true,
          "file": "/Volumes/VIXinSSD/demyst/examples/swarm_collapse.py"
        },
        {
          "type": "mean",
          "line": 35,
          "function": "anscombe_mirage",
          "description": "Reduction on array-like data without accompanying dispersion check.",
          "recommendation": "Use VariationTensor to preserve statistical metadata during aggregations",
          "confidence": "medium",
          "blocking": true,
          "file": "/Volumes/VIXinSSD/demyst/examples/real_world_mirages.py"
        },
        {
          "type": "mean",
          "line": 36,
          "function": "anscombe_mirage",
          "description": "Reduction on array-like data without accompanying dispersion check.",
          "recommendation": "Use VariationTensor to preserve statistical metadata during aggregations",
          "confidence": "medium",
          "blocking": true,
          "file": "/Volumes/VIXinSSD/demyst/examples/real_world_mirages.py"
        },
        {
          "type": "mean",
          "line": 37,
          "function": "anscombe_mirage",
          "description": "Reduction on array-like data without accompanying dispersion check.",
          "recommendation": "Use VariationTensor to preserve statistical metadata during aggregations",
          "confidence": "medium",
          "blocking": true,
          "file": "/Volumes/VIXinSSD/demyst/examples/real_world_mirages.py"
        },
        {
          "type": "mean",
          "line": 38,
          "function": "anscombe_mirage",
          "description": "Reduction on array-like data without accompanying dispersion check.",
          "recommendation": "Use VariationTensor to preserve statistical metadata during aggregations",
          "confidence": "medium",
          "blocking": true,
          "file": "/Volumes/VIXinSSD/demyst/examples/real_world_mirages.py"
        },
        {
          "type": "mean",
          "line": 61,
          "function": "simpsons_paradox_mirage",
          "description": "Reduction on array-like data without accompanying dispersion check.",
          "recommendation": "Use VariationTensor to preserve statistical metadata during aggregations",
          "confidence": "high",
          "blocking": true,
          "file": "/Volumes/VIXinSSD/demyst/examples/real_world_mirages.py"
        },
        {
          "type": "mean",
          "line": 149,
          "function": "climate_extremes_mirage",
          "description": "Reduction on array-like data without accompanying dispersion check.",
          "recommendation": "Use VariationTensor to preserve statistical metadata during aggregations",
          "confidence": "medium",
          "blocking": true,
          "file": "/Volumes/VIXinSSD/demyst/examples/real_world_mirages.py"
        },
        {
          "type": "mean",
          "line": 150,
          "function": "climate_extremes_mirage",
          "description": "Reduction on array-like data without accompanying dispersion check.",
          "recommendation": "Use VariationTensor to preserve statistical metadata during aggregations",
          "confidence": "medium",
          "blocking": true,
          "file": "/Volumes/VIXinSSD/demyst/examples/real_world_mirages.py"
        },
        {
          "type": "mean",
          "line": 176,
          "function": "swarm_safety_mirage",
          "description": "Reduction on array-like data without accompanying dispersion check.",
          "recommendation": "Use VariationTensor to preserve statistical metadata during aggregations",
          "confidence": "medium",
          "blocking": true,
          "file": "/Volumes/VIXinSSD/demyst/examples/real_world_mirages.py"
        },
        {
          "type": "sum",
          "line": 211,
          "function": "demonstrate_gradient_death",
          "description": "Reduction on array-like data without accompanying dispersion check.",
          "recommendation": "Use VariationTensor to preserve statistical metadata during aggregations",
          "confidence": "low",
          "blocking": false,
          "file": "/Volumes/VIXinSSD/demyst/examples/deep_learning_gradient_death.py"
        },
        {
          "type": "sum",
          "line": 227,
          "function": "demonstrate_gradient_death",
          "description": "Reduction on array-like data without accompanying dispersion check.",
          "recommendation": "Use VariationTensor to preserve statistical metadata during aggregations",
          "confidence": "low",
          "blocking": false,
          "file": "/Volumes/VIXinSSD/demyst/examples/deep_learning_gradient_death.py"
        },
        {
          "type": "mean",
          "line": 172,
          "function": "train_with_sklearn_pipeline",
          "description": "Reduction on array-like data without accompanying dispersion check.",
          "recommendation": "Use VariationTensor to preserve statistical metadata during aggregations",
          "confidence": "low",
          "blocking": false,
          "file": "/Volumes/VIXinSSD/demyst/examples/ml_data_leakage.py"
        },
        {
          "type": "premature_discretization",
          "line": 18,
          "function": "analyze_random_walk",
          "description": "Rounding/forcing int on data that appears array-like.",
          "recommendation": "Use VariationTensor to preserve statistical metadata during aggregations",
          "confidence": "low",
          "blocking": false,
          "file": "/Volumes/VIXinSSD/demyst/examples/random_walk.py"
        }
      ],
      "recommendations": [
        "Use VariationTensor to preserve statistical metadata during aggregations",
        "Track variance and distribution information alongside mean values"
      ]
    },
    {
      "name": "Deep Learning Integrity",
      "passed": false,
      "severity": "warning",
      "issues": [
        {
          "layer": "BatchNorm1d",
          "line": 114,
          "type": "unstable_batch_stats",
          "description": "BatchNorm1d with track_running_stats=False will use batch statistics during evaluation, causing non-deterministic behavior.",
          "masked_statistics": [
            "running_mean",
            "running_var"
          ],
          "recommendation": "Keep track_running_stats=True for production models. Batch statistics during eval hide distribution shifts between training and deployment data.",
          "confidence": "medium",
          "blocking": false,
          "file": "/Volumes/VIXinSSD/demyst/examples/deep_learning_gradient_death.py"
        }
      ],
      "recommendations": [
        "Add residual connections to prevent gradient death",
        "Monitor gradient flow during training with TorchModuleWrapper"
      ]
    },
    {
      "name": "Data Leakage",
      "passed": false,
      "severity": "critical",
      "issues": [
        {
          "type": "test_in_training",
          "severity": "critical",
          "line": 111,
          "col": 0,
          "variable": "X_test",
          "source": "Line 106",
          "context": "train",
          "description": "Test data 'X_test' is being used in training context 'train'. This completely invalidates your benchmark results.",
          "scientific_impact": "Your model has seen the test data during training. Any reported accuracy/performance metrics are meaningless. This is the most common form of scientific fraud in ML (often unintentional).",
          "recommendation": "Ensure complete separation of test data. Use sklearn's train_test_split or similar and verify test indices never appear in training loops.",
          "confidence": "high",
          "blocking": true,
          "file": "/Volumes/VIXinSSD/demyst/examples/ml_data_leakage.py"
        },
        {
          "type": "test_in_training",
          "severity": "critical",
          "line": 111,
          "col": 0,
          "variable": "y_test",
          "source": "Line 106",
          "context": "train",
          "description": "Test data 'y_test' is being used in training context 'train'. This completely invalidates your benchmark results.",
          "scientific_impact": "Your model has seen the test data during training. Any reported accuracy/performance metrics are meaningless. This is the most common form of scientific fraud in ML (often unintentional).",
          "recommendation": "Ensure complete separation of test data. Use sklearn's train_test_split or similar and verify test indices never appear in training loops.",
          "confidence": "high",
          "blocking": true,
          "file": "/Volumes/VIXinSSD/demyst/examples/ml_data_leakage.py"
        },
        {
          "type": "preprocessing_leakage",
          "severity": "critical",
          "line": 46,
          "col": 0,
          "variable": "X",
          "source": "fit_transform",
          "context": "preprocessing",
          "description": "fit_transform() called on line 46 BEFORE train_test_split on line 49. Preprocessing statistics (mean, std, etc.) are computed using test data.",
          "scientific_impact": "Preprocessing learns from test data. Features are scaled/normalized using information that should be held out. This is subtle but causes overestimation of model performance.",
          "recommendation": "Split data FIRST, then fit preprocessing on train only:\n  X_train, X_test = train_test_split(X)\n  scaler.fit(X_train)  X_train = scaler.transform(X_train)  X_test = scaler.transform(X_test)",
          "confidence": "high",
          "blocking": true,
          "file": "/Volumes/VIXinSSD/demyst/examples/ml_data_leakage.py"
        },
        {
          "type": "preprocessing_leakage",
          "severity": "critical",
          "line": 77,
          "col": 0,
          "variable": "X",
          "source": "fit_transform",
          "context": "preprocessing",
          "description": "fit_transform() called on line 77 BEFORE train_test_split on line 80. Preprocessing statistics (mean, std, etc.) are computed using test data.",
          "scientific_impact": "Preprocessing learns from test data. Features are scaled/normalized using information that should be held out. This is subtle but causes overestimation of model performance.",
          "recommendation": "Split data FIRST, then fit preprocessing on train only:\n  X_train, X_test = train_test_split(X)\n  scaler.fit(X_train)  X_train = scaler.transform(X_train)  X_test = scaler.transform(X_test)",
          "confidence": "high",
          "blocking": true,
          "file": "/Volumes/VIXinSSD/demyst/examples/ml_data_leakage.py"
        },
        {
          "type": "preprocessing_leakage",
          "severity": "critical",
          "line": 141,
          "col": 0,
          "variable": "X_train_scaled",
          "source": "fit_transform",
          "context": "cross_validation",
          "description": "fit_transform() called on line 141 BEFORE cross_val_score on line 170. Feature selection or scaling must happen INSIDE the CV loop.",
          "scientific_impact": "CV folds are contaminated with global statistics.",
          "recommendation": "Use sklearn Pipeline for CV.",
          "confidence": "high",
          "blocking": true,
          "file": "/Volumes/VIXinSSD/demyst/examples/ml_data_leakage.py"
        }
      ],
      "recommendations": [
        "Split data BEFORE any preprocessing or feature engineering",
        "Use sklearn Pipeline to ensure proper cross-validation"
      ]
    },
    {
      "name": "Statistical Validity",
      "passed": false,
      "severity": "critical",
      "issues": [
        {
          "type": "conditional_reporting",
          "severity": "questionable",
          "line": 25,
          "description": "Conditional logic based on p-value detected. This pattern enables selective reporting.",
          "statistical_impact": "Conditioning on significance leads to publication bias. Non-significant results are equally important for science.",
          "corrected_interpretation": "Report ALL results regardless of significance. Use pre-registration to prevent outcome-dependent analysis.",
          "recommendation": "Remove conditional branching on p-values. Report effect sizes and confidence intervals instead of just significance.",
          "confidence": "medium",
          "blocking": false,
          "file": "/Volumes/VIXinSSD/demyst/examples/biology_gene_expression.py"
        },
        {
          "type": "selective_early_exit_on_significance",
          "severity": "invalid",
          "line": 25,
          "description": "Loop aborts or reports immediately when a p-value passes the threshold. This is a classic p-hacking pattern.",
          "statistical_impact": "Early stopping on significance inflates false positives and biases estimates.",
          "corrected_interpretation": "Remove early exits; collect all results and correct p-values after.",
          "recommendation": "Accumulate results, apply multiple-comparison correction after the loop, and pre-register stopping rules.",
          "confidence": "high",
          "blocking": true,
          "file": "/Volumes/VIXinSSD/demyst/examples/biology_gene_expression.py"
        }
      ],
      "recommendations": [
        "Apply Bonferroni correction for multiple comparisons",
        "Report mean and std across multiple seeds, not best result"
      ]
    },
    {
      "name": "Dimensional Consistency",
      "passed": false,
      "severity": "critical",
      "issues": [
        {
          "type": "incompatible_addition",
          "severity": "critical",
          "line": 13,
          "col": 17,
          "expression": "0.5 * g * time_seconds ** 2 + 5.0",
          "left_dimension": "[M T]",
          "right_dimension": "[1]",
          "description": "Cannot add quantities with dimensions [M T] and [1].",
          "physical_meaning": "This is like adding apples to oranges. The result has no physical meaning.",
          "recommendation": "Check for missing unit conversions. Ensure both operands represent the same physical quantity.",
          "confidence": "high",
          "blocking": true,
          "file": "/Volumes/VIXinSSD/demyst/examples/physics_kinematics.py"
        },
        {
          "type": "incompatible_addition",
          "severity": "critical",
          "line": 17,
          "col": 19,
          "expression": "distance_x + time_seconds",
          "left_dimension": "[L]",
          "right_dimension": "[T]",
          "description": "Cannot add quantities with dimensions [L] and [T].",
          "physical_meaning": "This is like adding meters to seconds. The result has no physical meaning.",
          "recommendation": "Check for missing unit conversions. Ensure both operands represent the same physical quantity.",
          "confidence": "high",
          "blocking": true,
          "file": "/Volumes/VIXinSSD/demyst/examples/physics_kinematics.py"
        },
        {
          "type": "dimension_mismatch",
          "severity": "warning",
          "line": 24,
          "col": 4,
          "expression": "force_impact = 0.5 * mass_kg * velocity_mps ** 2",
          "left_dimension": "[L M T^-2]",
          "right_dimension": "[L M T^-1]",
          "description": "Variable 'force_impact' expects dimension [L M T^-2] but is assigned value with dimension [L M T^-1].",
          "physical_meaning": "Assignment violates annotated or inferred dimension; likely missing conversion.",
          "recommendation": "Ensure RHS has the same dimension or convert explicitly.",
          "confidence": "low",
          "blocking": false,
          "file": "/Volumes/VIXinSSD/demyst/examples/physics_kinematics.py"
        },
        {
          "type": "incompatible_addition",
          "severity": "critical",
          "line": 11,
          "col": 22,
          "expression": "mass_g + moles",
          "left_dimension": "[M]",
          "right_dimension": "[1]",
          "description": "Cannot add quantities with dimensions [M] and [1].",
          "physical_meaning": "This is like adding apples to oranges. The result has no physical meaning.",
          "recommendation": "Check for missing unit conversions. Ensure both operands represent the same physical quantity.",
          "confidence": "high",
          "blocking": true,
          "file": "/Volumes/VIXinSSD/demyst/examples/chemistry_stoichiometry.py"
        }
      ],
      "recommendations": [
        "Add explicit unit annotations to variable names",
        "Use dimensional analysis to catch physics errors"
      ]
    }
  ],
  "verdict": "FAIL: Blocking scientific integrity issues detected",
  "badge_status": "failing"
}